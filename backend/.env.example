# EcoSage Environment Variables â€” No API Key Required! ğŸ‰
# Copy this to .env  â†’  cp .env.example .env

# â”€â”€ Ollama settings (all local, all free) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OLLAMA_URL=http://localhost:11434

# The chat LLM â€” options ranked by quality vs speed:
#   llama3.2       (~2.0 GB)  â† recommended, great quality
#   llama3.2:1b    (~1.3 GB)  â† faster, lower RAM usage
#   mistral        (~4.1 GB)  â† very good quality
#   phi3           (~2.3 GB)  â† good and fast
#   gemma3:1b      (~815 MB)  â† lightest option
LLM_MODEL=llama3.2

# The embedding model â€” nomic-embed-text is the best free local option
EMBED_MODEL=nomic-embed-text

# How many knowledge base docs to retrieve per query (2-6 recommended)
TOP_K_DOCS=4

# â”€â”€ Server settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HOST=0.0.0.0
PORT=8000
